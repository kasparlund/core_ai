{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# notebook minist and different optimizers\n",
    "\n",
    "the basis is kaiminig optimization and batchnorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import torch\n",
    "from torch import *\n",
    "\n",
    "#let me be on my mac\n",
    "def cuda(self, device=None, non_blocking=False) : return self\n",
    "torch.Tensor.cuda = cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.modelmanager import *\n",
    "from lib.model import *\n",
    "from lib.data import *\n",
    "from lib.optimizers import *\n",
    "from lib.callbacks import *\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## mnist data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(-6.2598e-06), tensor(1.))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#x_train,y_train,x_valid,y_valid = load_pickled_train_valid_data(Path(\"/Users/kasparlund/.fastai/data/mnist.pkl.gz\"))\n",
    "x_train,y_train,x_valid,y_valid = load_pickled_train_valid_data(Path(\"C:/Users/kl/.fastai/data/mnist.pkl.gz\"))\n",
    "train_mean, train_sd = x_train.mean(), x_train.std()\n",
    "x_train   = normalize( x_train, train_mean, train_sd)\n",
    "x_valid   = normalize( x_valid, train_mean, train_sd)\n",
    "\n",
    "x_train.mean(),x_train.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98\n",
      "10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nh,bs              = 50,512\n",
    "train_ds,valid_ds  = Dataset(x_train, y_train),Dataset(x_valid, y_valid)\n",
    "train_dl, valid_dl = ( DataLoader( train_ds, batch_size=bs, shuffle=True), \n",
    "                        DataLoader(valid_ds,  batch_size=bs*2) )\n",
    "data               = DataBunch( train_dl, valid_dl, c_in=1, c_out=y_train.max().item()+1 )\n",
    "print(len(train_dl)), print(len(valid_dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For equal distribution of cases pr class:\n",
      "initial loss:    2.3025850929940455\n",
      "initial accuracy 0.1\n"
     ]
    }
   ],
   "source": [
    "# average loss pr input sample at iteration 0\n",
    "nb_classes = 10\n",
    "initial_loss = -np.log( 1.0/nb_classes ) \n",
    "print(f\"For equal distribution of cases pr class:\\ninitial loss:    {initial_loss}\\ninitial accuracy {1.0/nb_classes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "mnist_view   = view_tfm(1,28,28)\n",
    "layers_sizes = [8,16,32,32]\n",
    "loss_func    = F.cross_entropy\n",
    "sched        = combine_scheds([0.3, 0.7], [sched_cos(0.3, 0.6), sched_cos(0.6, 0.2)]) \n",
    "\n",
    "cbfs         = [TrainableModelCallback, TrainEvalCallback, OptimizerCallback, \n",
    "                partial(CudaCallback, device= torch.device('cuda',0)),\n",
    "#                SimpleCudaCallback,\n",
    "#                partial(ParamScheduler, 'lr', sched),\n",
    "                partial(BatchTransformXCallback, tfm = mnist_view), \n",
    "#                partial(MixUp,Î±=0.4),\n",
    "#                LR_Finder,\n",
    "                Recorder, \n",
    "                partial(AvgStatsCallback,[accuracy]),\n",
    "                ProgressCallback\n",
    "               ]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## resnets + steppers=[sgd_step]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "opt = SGD(sched,max_lr=0.5)#0.5)\n",
    "#loss_func=LabelSmoothingCrossEntropy()\n",
    "loss_func=F.cross_entropy\n",
    "\n",
    "layer = partial( conv_layer, stride=2, bn=False, zero_bn=False, act=GeneralRelu )\n",
    "from torch import *\n",
    "layer = partial( conv_layer, stride=2, bn=False, zero_bn=False, act=partial(torch.nn.ReLU,inplace=True) )\n",
    "model = partial(xresnet18, c_in=data.c_in, c_out=data.c_out)()\n",
    "#model = get_cnn_model(layers_sizes, data.c_in, data.c_out, layer=layer)\n",
    "mm    = CnnModelManager( model )\n",
    "mm.initialize(is_resnet=True)\n",
    "\n",
    "\n",
    "xb,_ = mm.getFirstbatch( data, normalization = mnist_view)\n",
    "print(f\"xb.shape:{xb.shape}\")\n",
    "mm.summary(xb, print_mod=False)\n",
    "learn = Learner( mm.model, data, loss_func=loss_func)\n",
    "\n",
    "%time learn.fit(25, opt=opt, cb_funcs=cbfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#learn.find_subcription_by_cls(LR_Finder).plot_loss(),plt.show()\n",
    "learn.find_subcription_by_cls(Recorder).plot_loss(),plt.show()\n",
    "learn.find_subcription_by_cls(Recorder).plot_lr(),plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "hidden": true
   },
   "source": [
    "SGD(sched,max_lr=0.5) e25 ReLU       with BN\n",
    "23\t0.002126\t0.999920\t0.041631\t0.988600\t00:14\n",
    "24\t0.001948\t0.999940\t0.040949\t0.988600\t00:14\n",
    "\n",
    "SGD(sched,max_lr=0.5) e25 ReLUOffset with BN\n",
    "23\t0.002756\t0.999820\t0.036769\t0.989300\t00:15\n",
    "24\t0.002654\t0.999820\t0.036812\t0.988900\t00:15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## steppers=[sgd_step]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "mm    = CnnModelManager( get_cnn_model(layers_sizes, data.c_in, data.c_out, layer=layer) )\n",
    "mm.initialize(is_resnet=False)\n",
    "opt = SGD(sched,max_lr=0.8)#0.5)\n",
    "\n",
    "#loss_func=LabelSmoothingCrossEntropy()\n",
    "loss_func=F.cross_entropy\n",
    "learn = Learner( mm.model, data, loss_func=loss_func)\n",
    "\n",
    "%time learn.fit(3, opt=opt,cb_funcs=cbfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#learn.find_subcription_by_cls(LR_Finder).plot_loss(),plt.show()\n",
    "learn.find_subcription_by_cls(Recorder).plot_loss(),plt.show()\n",
    "learn.find_subcription_by_cls(Recorder).plot_lr(),plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## steppers=[weight_decay, sgd_step]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "mm    = CnnModelManager( get_cnn_model(layers_sizes, data.c_in, data.c_out, layer=layer) )\n",
    "mm.initialize(is_resnet=False)\n",
    "\n",
    "opt = SGD(sched,max_lr=0.5, max_wd=0.01)\n",
    "#print(opt.hypers[0]['lr']), print(opt.hypers[0]['wd'])\n",
    "learn = Learner( mm.model, data, loss_func=F.cross_entropy)\n",
    "%time learn.fit(1, opt=opt,cb_funcs=cbfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn.find_subcription_by_cls(Recorder).plot_lr(),plt.show()\n",
    "learn.find_subcription_by_cls(Recorder).plot_loss(),plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## momentum: steppers=[momentum_step,weight_decay]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "mm    = CnnModelManager( get_cnn_model(layers_sizes, data.c_in, data.c_out, layer=layer) )\n",
    "mm.initialize(is_resnet=False)\n",
    "\n",
    "opt   = SGD_Momentum(sched,max_lr=1.0, moms=(0.85,0.95), max_wd=1e-3 )\n",
    "learn = Learner( mm.model, data, loss_func=F.cross_entropy)\n",
    "%time learn.fit(1, opt=opt, cb_funcs=cbfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#learn.find_subcription_by_cls(LR_Finder).plot_loss(skip_end=0),plt.show()\n",
    "learn.find_subcription_by_cls(Recorder).plot_loss(),plt.show()\n",
    "learn.find_subcription_by_cls(Recorder).plot_lr(),plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adam: steppers=[adam_step]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='54' class='' max='100', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      54.00% [54/100 03:05<02:37]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>valid_accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.132474</td>\n",
       "      <td>0.709220</td>\n",
       "      <td>0.306711</td>\n",
       "      <td>0.960500</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.227979</td>\n",
       "      <td>0.967740</td>\n",
       "      <td>0.118000</td>\n",
       "      <td>0.977600</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.139760</td>\n",
       "      <td>0.978360</td>\n",
       "      <td>0.086372</td>\n",
       "      <td>0.981400</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.113617</td>\n",
       "      <td>0.983380</td>\n",
       "      <td>0.068686</td>\n",
       "      <td>0.982300</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.101348</td>\n",
       "      <td>0.986720</td>\n",
       "      <td>0.059495</td>\n",
       "      <td>0.984400</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.093826</td>\n",
       "      <td>0.988200</td>\n",
       "      <td>0.058919</td>\n",
       "      <td>0.983900</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.091188</td>\n",
       "      <td>0.989340</td>\n",
       "      <td>0.055250</td>\n",
       "      <td>0.985500</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.084468</td>\n",
       "      <td>0.991000</td>\n",
       "      <td>0.048234</td>\n",
       "      <td>0.987700</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.080122</td>\n",
       "      <td>0.992440</td>\n",
       "      <td>0.046802</td>\n",
       "      <td>0.986600</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.076858</td>\n",
       "      <td>0.992580</td>\n",
       "      <td>0.054112</td>\n",
       "      <td>0.985500</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.080021</td>\n",
       "      <td>0.991800</td>\n",
       "      <td>0.055703</td>\n",
       "      <td>0.985800</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.073901</td>\n",
       "      <td>0.994000</td>\n",
       "      <td>0.046298</td>\n",
       "      <td>0.988400</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.075358</td>\n",
       "      <td>0.993860</td>\n",
       "      <td>0.056081</td>\n",
       "      <td>0.984200</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.072876</td>\n",
       "      <td>0.993900</td>\n",
       "      <td>0.051240</td>\n",
       "      <td>0.986200</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.072980</td>\n",
       "      <td>0.993200</td>\n",
       "      <td>0.050027</td>\n",
       "      <td>0.986500</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.073969</td>\n",
       "      <td>0.994120</td>\n",
       "      <td>0.047622</td>\n",
       "      <td>0.987100</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.068508</td>\n",
       "      <td>0.995300</td>\n",
       "      <td>0.051316</td>\n",
       "      <td>0.986800</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.071847</td>\n",
       "      <td>0.994440</td>\n",
       "      <td>0.053091</td>\n",
       "      <td>0.985400</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.069191</td>\n",
       "      <td>0.994560</td>\n",
       "      <td>0.048095</td>\n",
       "      <td>0.987100</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.071454</td>\n",
       "      <td>0.994280</td>\n",
       "      <td>0.049031</td>\n",
       "      <td>0.987600</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.068638</td>\n",
       "      <td>0.994600</td>\n",
       "      <td>0.051593</td>\n",
       "      <td>0.986700</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.064861</td>\n",
       "      <td>0.995420</td>\n",
       "      <td>0.057451</td>\n",
       "      <td>0.984200</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.067142</td>\n",
       "      <td>0.995800</td>\n",
       "      <td>0.059169</td>\n",
       "      <td>0.985000</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.067596</td>\n",
       "      <td>0.995120</td>\n",
       "      <td>0.049005</td>\n",
       "      <td>0.986200</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.068995</td>\n",
       "      <td>0.994900</td>\n",
       "      <td>0.047104</td>\n",
       "      <td>0.987600</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.066528</td>\n",
       "      <td>0.995540</td>\n",
       "      <td>0.056329</td>\n",
       "      <td>0.985000</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.067681</td>\n",
       "      <td>0.995960</td>\n",
       "      <td>0.046966</td>\n",
       "      <td>0.987700</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.066778</td>\n",
       "      <td>0.995740</td>\n",
       "      <td>0.047221</td>\n",
       "      <td>0.988100</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.066572</td>\n",
       "      <td>0.995760</td>\n",
       "      <td>0.047912</td>\n",
       "      <td>0.987600</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.065681</td>\n",
       "      <td>0.996000</td>\n",
       "      <td>0.044476</td>\n",
       "      <td>0.988500</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.063694</td>\n",
       "      <td>0.996500</td>\n",
       "      <td>0.044392</td>\n",
       "      <td>0.989000</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>0.064576</td>\n",
       "      <td>0.996460</td>\n",
       "      <td>0.051763</td>\n",
       "      <td>0.986500</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.066184</td>\n",
       "      <td>0.996240</td>\n",
       "      <td>0.053259</td>\n",
       "      <td>0.986100</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>0.063180</td>\n",
       "      <td>0.996240</td>\n",
       "      <td>0.048891</td>\n",
       "      <td>0.988000</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>0.061202</td>\n",
       "      <td>0.996840</td>\n",
       "      <td>0.056827</td>\n",
       "      <td>0.984900</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>0.064575</td>\n",
       "      <td>0.996440</td>\n",
       "      <td>0.052067</td>\n",
       "      <td>0.987000</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>0.061760</td>\n",
       "      <td>0.996600</td>\n",
       "      <td>0.056785</td>\n",
       "      <td>0.985700</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>0.060702</td>\n",
       "      <td>0.996940</td>\n",
       "      <td>0.043437</td>\n",
       "      <td>0.989100</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>0.062604</td>\n",
       "      <td>0.996880</td>\n",
       "      <td>0.044234</td>\n",
       "      <td>0.989200</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>0.061159</td>\n",
       "      <td>0.996960</td>\n",
       "      <td>0.041790</td>\n",
       "      <td>0.990800</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.061791</td>\n",
       "      <td>0.997100</td>\n",
       "      <td>0.042256</td>\n",
       "      <td>0.989800</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>0.062079</td>\n",
       "      <td>0.996920</td>\n",
       "      <td>0.048306</td>\n",
       "      <td>0.988300</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>0.063432</td>\n",
       "      <td>0.997380</td>\n",
       "      <td>0.045550</td>\n",
       "      <td>0.990400</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>0.057412</td>\n",
       "      <td>0.997460</td>\n",
       "      <td>0.048533</td>\n",
       "      <td>0.988900</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>0.062175</td>\n",
       "      <td>0.996860</td>\n",
       "      <td>0.044435</td>\n",
       "      <td>0.989000</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>0.061781</td>\n",
       "      <td>0.997600</td>\n",
       "      <td>0.041854</td>\n",
       "      <td>0.989500</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>0.059664</td>\n",
       "      <td>0.997780</td>\n",
       "      <td>0.047155</td>\n",
       "      <td>0.988700</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>0.062380</td>\n",
       "      <td>0.996360</td>\n",
       "      <td>0.044081</td>\n",
       "      <td>0.989600</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>0.060861</td>\n",
       "      <td>0.997680</td>\n",
       "      <td>0.045433</td>\n",
       "      <td>0.989400</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>0.057969</td>\n",
       "      <td>0.998080</td>\n",
       "      <td>0.044430</td>\n",
       "      <td>0.988900</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.059424</td>\n",
       "      <td>0.997260</td>\n",
       "      <td>0.045062</td>\n",
       "      <td>0.988600</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51</td>\n",
       "      <td>0.059533</td>\n",
       "      <td>0.997540</td>\n",
       "      <td>0.041852</td>\n",
       "      <td>0.990100</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52</td>\n",
       "      <td>0.059848</td>\n",
       "      <td>0.998060</td>\n",
       "      <td>0.048043</td>\n",
       "      <td>0.988700</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53</td>\n",
       "      <td>0.057662</td>\n",
       "      <td>0.998020</td>\n",
       "      <td>0.042813</td>\n",
       "      <td>0.990000</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='31' class='' max='98', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      31.63% [31/98 00:01<00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "activ_func = partial(ReLUOffset) \n",
    "#activ_func = partial(nn.ReLU,inplace=True)\n",
    "model = partial(xresnet18, c_in=data.c_in, c_out=data.c_out, activ_func=activ_func)()\n",
    "#model = get_cnn_model(layers_sizes, data.c_in, data.c_out, layer=layer)\n",
    "mm    = CnnModelManager( model )\n",
    "mm.initialize(is_resnet=True)\n",
    "\n",
    "opt   = Adam(sched,max_lr=3e-3, moms=(0.85,0.95), max_wd = 0)#1e-6)\n",
    "learn = Learner( mm.model, data, loss_func=F.cross_entropy)\n",
    "#%time learn.fit(10, opt=opt, cb_funcs=cbfs)\n",
    "%time learn.fit(100, opt=opt, cb_funcs=cbfs.copy()+[partial(MixUp,Î±=0.01)])\n",
    "\n",
    "#%time learn.fit(1, opt=opt, cb_funcs=cbfs.copy()+[LRFinder])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "epoch\ttrain_loss\ttrain_accuracy\tvalid_loss\tvalid_accuracy\ttime\n",
    "0\t1.353850\t0.730620\t0.405658\t0.950600\t00:17\n",
    "1\t0.234322\t0.966680\t0.113542\t0.977700\t00:16\n",
    "2\t0.129991\t0.979400\t0.082061\t0.981800\t00:15\n",
    "3\t0.105302\t0.983980\t0.061779\t0.983500\t00:15\n",
    "4\t0.095386\t0.987160\t0.064079\t0.982200\t00:16\n",
    "5\t0.090190\t0.988500\t0.050798\t0.985800\t00:16\n",
    "6\t0.081243\t0.991120\t0.043561\t0.988400\t00:16\n",
    "7\t0.075539\t0.992840\t0.045033\t0.987400\t00:16\n",
    "8\t0.075034\t0.994000\t0.043906\t0.987500\t00:17\n",
    "9\t0.070595\t0.995160\t0.038814\t0.989700\t00:17\n",
    "\n",
    "\n",
    "e10 ReLU       with BN with Adam(sched,max_lr=3e-3, moms=(0.85,0.95), max_wd = 0)\n",
    "0\t1.325691\t0.710080\t0.365646\t0.948500\t00:16\n",
    "8\t0.011932\t0.996680\t0.053259\t0.984300\t00:15\n",
    "9\t0.008680\t0.997780\t0.043023\t0.989000\t00:16\n",
    "    \n",
    "e10 ReLUOffset with BN with Adam(sched,max_lr=3e-3, moms=(0.85,0.95), max_wd = 0)\n",
    "0\t1.375782\t0.719920\t0.412933\t0.955200\t00:16\n",
    "8\t0.010508\t0.997160\t0.041148\t0.989100\t00:15\n",
    "9\t0.008267\t0.997740\t0.043017\t0.988100\t00:16\n",
    "\n",
    "\n",
    "e10 ReLU       with BN with Adam(sched,max_lr=3e-3, moms=(0.85,0.95), max_wd=0), mixup=0.2\n",
    "\n",
    "e10 ReLU       with BN with Adam(sched,max_lr=3e-3, moms=(0.85,0.95), max_wd=0), mixup=0.4\n",
    "\n",
    "e10 ReLUOffset with BN with Adam(sched,max_lr=3e-3, moms=(0.85,0.95), max_wd=0), mixup=0.2\n",
    "\n",
    "e10 ReLUOffset with BN with Adam(sched,max_lr=3e-3, moms=(0.85,0.95), max_wd=0), mixup=0.4\n",
    "\n",
    "learn.find_subcription_by_cls(Recorder).plot_loss(),plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#learn.find_subcription_by_cls(LRFinder).plot_loss(skip_end=10),plt.show()\n",
    "learn.find_subcription_by_cls(Recorder).plot_loss(),plt.show()\n",
    "#learn.find_subcription_by_cls(Recorder).plot_lr(),plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "    \n",
    "e100 ReLU       with BN with Adam(sched,max_lr=3e-3, moms=(0.85,0.95), max_wd = 0)\n",
    "98\t0.000090\t1.000000\t0.069012\t0.989800\t00:15\n",
    "99\t0.000030\t1.000000\t0.067332\t0.990000\t00:15\n",
    "\n",
    "e100 ReLUOffset with BN with Adam(sched,max_lr=3e-3, moms=(0.85,0.95), max_wd = 0)\n",
    "98\t0.000007\t1.000000\t0.055621\t0.991600\t00:14\n",
    "99\t0.000006\t1.000000\t0.057216\t0.991200\t00:14\n",
    "\n",
    "e100 ReLU       with BN with Adam(sched,max_lr=3e-3, moms=(0.85,0.95), max_wd=0), mixup=0.2\n",
    "98\t0.455362\t0.986360\t0.119032\t0.990800\t00:14\n",
    "99\t0.454292\t0.986400\t0.126851\t0.990500\t00:14\n",
    "\n",
    "e100 ReLU       with BN with Adam(sched,max_lr=3e-3, moms=(0.85,0.95), max_wd=0), mixup=0.4\n",
    "98\t0.539563\t0.978840\t0.156997\t0.989800\t00:14\n",
    "99\t0.533668\t0.978680\t0.172270\t0.991300\t00:14\n",
    "\n",
    "e100 ReLUOffset with BN with Adam(sched,max_lr=3e-3, moms=(0.85,0.95), max_wd=0), mixup=0.2\n",
    "98\t0.446543\t0.988300\t0.122085\t0.990600\t00:14\n",
    "99\t0.449006\t0.987200\t0.114912\t0.991600\t00:14\n",
    "\n",
    "e100 ReLUOffset with BN with Adam(sched,max_lr=3e-3, moms=(0.85,0.95), max_wd=0), mixup=0.4\n",
    "98\t0.549706\t0.979020\t0.148965\t0.990500\t00:14\n",
    "99\t0.553123\t0.978200\t0.145417\t0.990500\t00:15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LAMB: steppers=[lamb_step]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's then super easy to implement a new optimizer. This is LAMB from a [very recent paper](https://arxiv.org/pdf/1904.00962.pdf):\n",
    "\n",
    "$\\begin{align}\n",
    "g_{t}^{l} &= \\nabla L(w_{t-1}^{l}, x_{t}) \\\\\n",
    "m_{t}^{l} &= \\beta_{1} m_{t-1}^{l} + (1-\\beta_{1}) g_{t}^{l} \\\\\n",
    "v_{t}^{l} &= \\beta_{2} v_{t-1}^{l} + (1-\\beta_{2}) g_{t}^{l} \\odot g_{t}^{l} \\\\\n",
    "m_{t}^{l} &= m_{t}^{l} / (1 - \\beta_{1}^{t}) \\\\\n",
    "v_{t}^{l} &= v_{t}^{l} / (1 - \\beta_{2}^{t}) \\\\\n",
    "r_{1} &= \\|w_{t-1}^{l}\\|_{2} \\\\\n",
    "s_{t}^{l} &= \\frac{m_{t}^{l}}{\\sqrt{v_{t}^{l} + \\epsilon}} + \\lambda w_{t-1}^{l} \\\\ \n",
    "r_{2} &= \\| s_{t}^{l} \\|_{2} \\\\\n",
    "\\eta^{l} &= \\eta * r_{1}/r_{2} \\\\ \n",
    "w_{t}^{l} &= w_{t}^{l-1} - \\eta_{l} * s_{t}^{l} \\\\\n",
    "\\end{align}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mm    = CnnModelManager( get_cnn_model(layers_sizes, data.c_in, data.c_out, layer=layer) )\n",
    "mm.initialize(is_resnet=False)\n",
    "\n",
    "opt   = LAMB(sched,max_lr=0.02, moms=(0.85,0.95), max_wd = 1e-4)     \n",
    "#opt   = LAMB(sched,max_lr=0.005, moms=(0.85,0.95), max_wd = 1e-4)     #with mixup\n",
    "learn = Learner( mm.model, data, loss_func=F.cross_entropy)\n",
    "%time learn.fit(1, opt=opt, cb_funcs=cbfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "learn.find_subcription_by_cls(Recorder).plot_loss(),plt.show()\n",
    "learn.find_subcription_by_cls(Recorder).plot_lr(),plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## mnist with adam and hooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#activ_func = partial(nn.ReLU,inplace=True) \n",
    "activ_func = partial(ReLUOffset) \n",
    "model = partial(xresnet18, c_in=data.c_in, c_out=data.c_out, activ_func=activ_func)()\n",
    "#model = get_cnn_model(layers_sizes, data.c_in, data.c_out, layer=layer)\n",
    "mm    = CnnModelManager( model )\n",
    "mm.initialize(is_resnet=True)# mm.initialize(is_resnet=False)\n",
    "\n",
    "#model = partial(xresnet18, c_in=data.c_in, c_out=data.c_out)()\n",
    "#opt   = Adam(sched,max_lr=0.05, moms=(0.85,0.95), max_wd = 1e-3)\n",
    "opt   = Adam(sched,max_lr=3e-3, moms=(0.85,0.95), max_wd = 0) #1e-5) # xresnet18\n",
    "learn = Learner( mm.model, data, loss_func=F.cross_entropy)\n",
    "with Hooks(mm.model, append_stats) as hooks: \n",
    "    #learn.fit(3, opt=opt, cb_funcs=cbfs.copy()+[partial(MixUp,Î±=0.01)])    \n",
    "    learn.fit(3, opt=opt, cb_funcs=cbfs)    \n",
    "    plot_layer_stats( hooks )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## mnist with LAMB and hooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#model = CnnModelManager( partial(xresnet18, c_in=data.c_in, c_out=data.c_out)() )\n",
    "mm    = CnnModelManager( get_cnn_model(layers_sizes, data.c_in, data.c_out, layer=layer) )\n",
    "mm.initialize(is_resnet=False)\n",
    "\n",
    "opt   = LAMB(sched,max_lr=0.008, moms=(0.85,0.95), max_wd = 1e-6)     \n",
    "learn = Learner( mm.model, data, loss_func=F.cross_entropy)\n",
    "with Hooks(mm.model, append_stats) as hooks: \n",
    "    learn.fit(3, opt=opt, cb_funcs=cbfs)\n",
    "    plot_layer_stats( hooks )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
