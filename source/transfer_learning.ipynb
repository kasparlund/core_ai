{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import *\n",
    "\n",
    "#let me be on my mac\n",
    "def cuda(self, device=None, non_blocking=False) : return self\n",
    "torch.Tensor.cuda = cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.modelmanager import *\n",
    "from lib.model import *\n",
    "from lib.callbacks import *\n",
    "from lib.data import *\n",
    "from lib.optimizers import *\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create basemodel on imagenette"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/Users/kasparlund/.fastai/data/imagewoof-160')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = datasets.untar_data(datasets.URLs.IMAGEWOOF_160)\n",
    "#path = untar_data(datasets.URLs.IMAGENETTE_160)\n",
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of training, validation images: 12454,  500\n",
      "imagenette_features:10\n"
     ]
    }
   ],
   "source": [
    "size = 128\n",
    "bs   = 64\n",
    "\n",
    "tfms     = [make_rgb, RandomResizedCrop(size, scale=(0.35,1)), PilRandomFlip(), to_byte_tensor, to_float_tensor]\n",
    "val_tfms = [make_rgb, CenterCrop(size), to_byte_tensor, to_float_tensor]\n",
    "files    = ImageList.from_files(path, tfms=tfms)\n",
    "\n",
    "sd       = SplitData.split_by_func(files, partial(grandparent_splitter, valid_name='val'))\n",
    "data     = label_train_valid_data(sd, parent_labeler, proc_y=CategoryProcessor())\n",
    "data.valid.x.tfms  = val_tfms\n",
    "\n",
    "imagenette_features = max(data.train.y)+1\n",
    "print(f\"number of training, validation images: {len(data.train)},  {len(data.valid)}\")\n",
    "print(f\"imagenette_features:{imagenette_features}\")\n",
    "\n",
    "train_dl,valid_dl = ( DataLoader(data.train, batch_size=bs,   num_workers=4, shuffle=True),\n",
    "                      DataLoader(data.valid, batch_size=bs*2, num_workers=4))\n",
    "databunch = DataBunch(train_dl, valid_dl, c_in=3, c_out=imagenette_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers_sizes = [64,64,128,256]\n",
    "layer = partial( conv_layer, stride=2, bn=True, zero_bn=False, act=partial(torch.nn.ReLU,inplace=True) )\n",
    "mm    = CnnModelManager( get_cnn_model(layers_sizes, databunch.c_in, databunch.c_out, layer) )\n",
    "mm.initialize(is_resnet=False)\n",
    "\n",
    "cbfs_base = [TrainableModelCallback, TrainEvalCallback, OptimizerCallback, \n",
    "#        partial(ParamScheduler, 'lr', sched),\n",
    "        partial(BatchTransformXCallback, norm_imagenette),\n",
    "#        partial(MixUp,Î±=0.4),\n",
    "        \n",
    "        #CudaCallback,\n",
    "        ProgressCallback,\n",
    "       ]\n",
    "cbfs = cbfs_base.copy() + [Recorder, partial(AvgStatsCallback,[accuracy])]\n",
    "cbfs_lr_Finder = cbfs_base.copy() + [LR_Finder]\n",
    "\n",
    "sched = combine_scheds([0.3, 0.7], [sched_cos(0.3, 0.6), sched_cos(0.6, 0.2)]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "requires_grad: True  : Conv2d\n",
      "requires_grad: True  : BatchNorm2d\n",
      "requires_grad: None  : ReLU\n",
      "requires_grad: True  : Conv2d\n",
      "requires_grad: True  : BatchNorm2d\n",
      "requires_grad: None  : ReLU\n",
      "requires_grad: True  : Conv2d\n",
      "requires_grad: True  : BatchNorm2d\n",
      "requires_grad: None  : ReLU\n",
      "requires_grad: True  : Conv2d\n",
      "requires_grad: True  : BatchNorm2d\n",
      "requires_grad: None  : ReLU\n",
      "requires_grad: None  : AdaptiveAvgPool2d\n",
      "requires_grad: None  : Lambda\n",
      "requires_grad: True  : Linear\n",
      "\n",
      "model hierarchy:\n",
      "Sequential(\n",
      "  (0): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), bias=False)\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace)\n",
      "  )\n",
      "  (1): Sequential(\n",
      "    (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace)\n",
      "  )\n",
      "  (2): Sequential(\n",
      "    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace)\n",
      "  )\n",
      "  (3): Sequential(\n",
      "    (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace)\n",
      "  )\n",
      "  (4): AdaptiveAvgPool2d(output_size=1)\n",
      "  (5): Lambda()\n",
      "  (6): Linear(in_features=256, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "mm.grads_summary()\n",
    "#xb,_ = getFirstbatch( model, databunch, partial(BatchTransformXCallback, tfm = norm_imagenette))\n",
    "#model_summary(model, xb, only_leaves=True, print_mod=False)\n",
    "print(f\"\\nmodel hierarchy:\\n{mm.model}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>valid_accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2.201428</td>\n",
       "      <td>0.211338</td>\n",
       "      <td>2.153249</td>\n",
       "      <td>0.232000</td>\n",
       "      <td>02:49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.067876</td>\n",
       "      <td>0.280071</td>\n",
       "      <td>2.090931</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>02:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.003838</td>\n",
       "      <td>0.321423</td>\n",
       "      <td>2.038854</td>\n",
       "      <td>0.280000</td>\n",
       "      <td>02:37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.954257</td>\n",
       "      <td>0.342219</td>\n",
       "      <td>1.975465</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>02:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.917405</td>\n",
       "      <td>0.363096</td>\n",
       "      <td>1.969318</td>\n",
       "      <td>0.328000</td>\n",
       "      <td>02:34</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 38min 13s, sys: 8min 29s, total: 46min 43s\n",
      "Wall time: 13min 5s\n"
     ]
    }
   ],
   "source": [
    "learn = Learner( mm.model, databunch, loss_func=LabelSmoothingCrossEntropy())\n",
    "%time learn.fit(5, opt=Adam(sched,max_lr=3e-4, moms=(0.85,0.95), max_wd = 1e-4), cb_funcs=cbfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "mm.save(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trains Pets dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pets = datasets.untar_data(datasets.URLs.PETS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('/Users/kasparlund/.fastai/data/oxford-iiit-pet/images'),\n",
       " PosixPath('/Users/kasparlund/.fastai/data/oxford-iiit-pet/annotations')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(pets.iterdir())[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('/Users/kasparlund/.fastai/data/oxford-iiit-pet/images/Egyptian_Mau_167.jpg'),\n",
       " PosixPath('/Users/kasparlund/.fastai/data/oxford-iiit-pet/images/pug_52.jpg'),\n",
       " PosixPath('/Users/kasparlund/.fastai/data/oxford-iiit-pet/images/basset_hound_112.jpg'),\n",
       " PosixPath('/Users/kasparlund/.fastai/data/oxford-iiit-pet/images/Siamese_193.jpg'),\n",
       " PosixPath('/Users/kasparlund/.fastai/data/oxford-iiit-pet/images/shiba_inu_122.jpg'),\n",
       " PosixPath('/Users/kasparlund/.fastai/data/oxford-iiit-pet/images/Siamese_53.jpg'),\n",
       " PosixPath('/Users/kasparlund/.fastai/data/oxford-iiit-pet/images/Birman_167.jpg'),\n",
       " PosixPath('/Users/kasparlund/.fastai/data/oxford-iiit-pet/images/leonberger_6.jpg'),\n",
       " PosixPath('/Users/kasparlund/.fastai/data/oxford-iiit-pet/images/Siamese_47.jpg'),\n",
       " PosixPath('/Users/kasparlund/.fastai/data/oxford-iiit-pet/images/shiba_inu_136.jpg')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pets_path = pets/'images'\n",
    "list(pets_path.iterdir())[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of training, validation images: 6698,  692\n",
      "pets_features:37\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "def random_splitter(fn, p_valid): return random.random() < p_valid\n",
    "def pet_labeler(fn): return re.findall(r'^(.*)_\\d+.jpg$', fn.name)[0]\n",
    "\n",
    "files = ImageList.from_files(pets_path, tfms=tfms)\n",
    "sd    = SplitData.split_by_func(files, partial(random_splitter, p_valid=0.1))\n",
    "\n",
    "proc  = CategoryProcessor()\n",
    "data  = label_train_valid_data(sd, pet_labeler, proc_y=proc)\n",
    "data.valid.x.tfms = val_tfms\n",
    "\n",
    "pets_features     = len(proc.vocab)\n",
    "print(f\"number of training, validation images: {len(data.train)},  {len(data.valid)}\")\n",
    "print(f\"pets_features:{pets_features}\")\n",
    "\n",
    "train_dl,valid_dl = ( DataLoader(data.train, batch_size=bs,   num_workers=4, shuffle=True),\n",
    "                      DataLoader(data.valid, batch_size=bs*2, num_workers=4))\n",
    "databunch = DataBunch(train_dl, valid_dl, c_in=3, c_out=pets_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "categories:\n",
      "Egyptian_Mau, pug, Siamese, shiba_inu, Birman, leonberger, saint_bernard, Abyssinian, miniature_pinscher, wheaten_terrier, scottish_terrier, pomeranian, german_shorthaired, english_setter, newfoundland, Sphynx, British_Shorthair, Bombay, boxer, great_pyrenees, samoyed, Russian_Blue, Persian, japanese_chin, Ragdoll, english_cocker_spaniel, Maine_Coon, havanese, Bengal, american_pit_bull_terrier, keeshond, american_bulldog, chihuahua, beagle, yorkshire_terrier, staffordshire_bull_terrier, basset_hound\n"
     ]
    }
   ],
   "source": [
    "print(f\"categories:\\n{ ', '.join(proc.vocab) }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train with from scratch\n",
    "mm    = CnnModelManager( get_cnn_model(layers_sizes, databunch.c_in, databunch.c_out, layer) )\n",
    "mm.initialize(is_resnet=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "requires_grad: True  : Conv2d\n",
      "requires_grad: True  : BatchNorm2d\n",
      "requires_grad: None  : ReLU\n",
      "requires_grad: True  : Conv2d\n",
      "requires_grad: True  : BatchNorm2d\n",
      "requires_grad: None  : ReLU\n",
      "requires_grad: True  : Conv2d\n",
      "requires_grad: True  : BatchNorm2d\n",
      "requires_grad: None  : ReLU\n",
      "requires_grad: True  : Conv2d\n",
      "requires_grad: True  : BatchNorm2d\n",
      "requires_grad: None  : ReLU\n",
      "requires_grad: None  : AdaptiveAvgPool2d\n",
      "requires_grad: None  : Lambda\n",
      "requires_grad: True  : Linear\n",
      "model hierarchy:\n",
      "Sequential(\n",
      "  (0): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), bias=False)\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace)\n",
      "  )\n",
      "  (1): Sequential(\n",
      "    (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace)\n",
      "  )\n",
      "  (2): Sequential(\n",
      "    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace)\n",
      "  )\n",
      "  (3): Sequential(\n",
      "    (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace)\n",
      "  )\n",
      "  (4): AdaptiveAvgPool2d(output_size=1)\n",
      "  (5): Lambda()\n",
      "  (6): Linear(in_features=256, out_features=37, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#xb,_ = getFirstbatch( learn.model, databunch, partial(BatchTransformXCallback, tfm = norm_imagenette))\n",
    "#model_summary(model, xb, only_leaves=True, print_mod=False)\n",
    "mm.grads_summary()\n",
    "print(f\"model hierarchy:\\n{mm.model}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>valid_accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>3.522268</td>\n",
       "      <td>0.067931</td>\n",
       "      <td>3.462243</td>\n",
       "      <td>0.073699</td>\n",
       "      <td>01:32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.364242</td>\n",
       "      <td>0.114512</td>\n",
       "      <td>3.400950</td>\n",
       "      <td>0.104046</td>\n",
       "      <td>01:31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8min 32s, sys: 2min 3s, total: 10min 35s\n",
      "Wall time: 3min 3s\n"
     ]
    }
   ],
   "source": [
    "learn = Learner( mm.model, databunch, loss_func=LabelSmoothingCrossEntropy() )\n",
    "cbfs  = cbfs_base.copy() + [Recorder, partial(AvgStatsCallback,[accuracy])]\n",
    "%time learn.fit(2, opt=Adam(sched,max_lr=3e-4, moms=(0.85,0.95), max_wd = 1e-4), cb_funcs=cbfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## use pretrained imagewoff model for training with gradual unfreezing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "path to pretrained model:/Users/kasparlund/.fastai/data/imagewoof-160\n"
     ]
    }
   ],
   "source": [
    "print(f\"path to pretrained model:{path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model hierarchy:\n",
      "Sequential(\n",
      "  (0): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), bias=False)\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace)\n",
      "  )\n",
      "  (1): Sequential(\n",
      "    (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace)\n",
      "  )\n",
      "  (2): Sequential(\n",
      "    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace)\n",
      "  )\n",
      "  (3): Sequential(\n",
      "    (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace)\n",
      "  )\n",
      "  (4): AdaptiveAvgPool2d(output_size=1)\n",
      "  (5): Lambda()\n",
      "  (6): Linear(in_features=256, out_features=10, bias=True)\n",
      ")\n",
      "requires_grad: True  : Conv2d\n",
      "requires_grad: True  : BatchNorm2d\n",
      "requires_grad: None  : ReLU\n",
      "requires_grad: True  : Conv2d\n",
      "requires_grad: True  : BatchNorm2d\n",
      "requires_grad: None  : ReLU\n",
      "requires_grad: True  : Conv2d\n",
      "requires_grad: True  : BatchNorm2d\n",
      "requires_grad: None  : ReLU\n",
      "requires_grad: True  : Conv2d\n",
      "requires_grad: True  : BatchNorm2d\n",
      "requires_grad: None  : ReLU\n",
      "requires_grad: None  : AdaptiveAvgPool2d\n",
      "requires_grad: None  : Lambda\n",
      "requires_grad: True  : Linear\n"
     ]
    }
   ],
   "source": [
    "#load pretrained on imagewoof\n",
    "mm    = CnnModelManager( get_cnn_model(layers_sizes, databunch.c_in, imagenette_features, layer) )\n",
    "mm.load(path)\n",
    "\n",
    "print(f\"model hierarchy:\\n{mm.model}\")\n",
    "mm.grads_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "mm.adapt_model(databunch, normalization=norm_imagenette)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "requires_grad: False : Conv2d\n",
      "requires_grad: True  : BatchNorm2d\n",
      "requires_grad: None  : ReLU\n",
      "requires_grad: False : Conv2d\n",
      "requires_grad: True  : BatchNorm2d\n",
      "requires_grad: None  : ReLU\n",
      "requires_grad: False : Conv2d\n",
      "requires_grad: True  : BatchNorm2d\n",
      "requires_grad: None  : ReLU\n",
      "requires_grad: False : Conv2d\n",
      "requires_grad: True  : BatchNorm2d\n",
      "requires_grad: None  : ReLU\n",
      "requires_grad: None  : AdaptiveAvgPool2d\n",
      "requires_grad: None  : Flatten\n",
      "requires_grad: True  : Linear\n"
     ]
    }
   ],
   "source": [
    "mm.freeze()\n",
    "mm.grads_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "cbfs  = cbfs_base.copy() + [Recorder, partial(AvgStatsCallback,[accuracy])]\n",
    "learn = Learner( mm.model, databunch, loss_func=LabelSmoothingCrossEntropy() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>valid_accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>3.451682</td>\n",
       "      <td>0.093610</td>\n",
       "      <td>3.302769</td>\n",
       "      <td>0.117052</td>\n",
       "      <td>01:15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 58s, sys: 44.5 s, total: 3min 42s\n",
      "Wall time: 1min 15s\n"
     ]
    }
   ],
   "source": [
    "%time learn.fit(1, opt=Adam(sched,max_lr=1e-2, moms=(0.85,0.95), max_wd = 1e-4), cb_funcs=cbfs)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "epoch\ttrain_loss\ttrain_accuracy\tvalid_loss\tvalid_accuracy\ttime\n",
    "0\t3.388485\t0.099083\t3.246178\t0.146143\t00:49"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "requires_grad: True  : Conv2d\n",
      "requires_grad: True  : BatchNorm2d\n",
      "requires_grad: None  : ReLU\n",
      "requires_grad: True  : Conv2d\n",
      "requires_grad: True  : BatchNorm2d\n",
      "requires_grad: None  : ReLU\n",
      "requires_grad: True  : Conv2d\n",
      "requires_grad: True  : BatchNorm2d\n",
      "requires_grad: None  : ReLU\n",
      "requires_grad: True  : Conv2d\n",
      "requires_grad: True  : BatchNorm2d\n",
      "requires_grad: None  : ReLU\n",
      "requires_grad: None  : AdaptiveAvgPool2d\n",
      "requires_grad: None  : Flatten\n",
      "requires_grad: True  : Linear\n"
     ]
    }
   ],
   "source": [
    "mm.unfreeze()\n",
    "mm.grads_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>valid_accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>3.267389</td>\n",
       "      <td>0.133473</td>\n",
       "      <td>3.271721</td>\n",
       "      <td>0.122832</td>\n",
       "      <td>01:41</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit(1, opt=Adam(sched,max_lr=5e-5, moms=(0.85,0.95), max_wd = 1e-6), cb_funcs=cbfs)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "epoch\ttrain_loss\ttrain_accuracy\tvalid_loss\tvalid_accuracy\ttime\n",
    "0\t3.198439\t0.156367\t3.217241\t0.162382\t01:07"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
